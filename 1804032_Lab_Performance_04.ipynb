{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "ihq_G7MfRJO5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vjs0MhNGHbUC"
      },
      "outputs": [],
      "source": [
        "def Split(df, testSize):\n",
        "    if isinstance(testSize, float):\n",
        "        testSize = round(testSize * len(df))\n",
        "    indices = df.index.tolist()\n",
        "    testIndices = random.sample(population = indices, k = testSize)\n",
        "    dfTest = df.loc[testIndices]\n",
        "    dfTrain = df.drop(testIndices)\n",
        "    return dfTrain, dfTest\n",
        "\n",
        "def puritycheck(data):\n",
        "    if len(numpy.unique(data[:, -1])) == 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def dataclassification(data):\n",
        "    uniqueClasses, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
        "    return uniqueClasses[uniqueClassesCounts.argmax()]\n",
        "\n",
        "def PotentialSplit(data, randomAttributes):\n",
        "    potentialSplits = {}\n",
        "    _, columns = data.shape\n",
        "    columnsIndices = list(range(columns - 1))\n",
        "    if randomAttributes != None  and len(randomAttributes) <= len(columnsIndices):\n",
        "        columnsIndices = randomAttributes\n",
        "    for column in columnsIndices:\n",
        "        values = data[:, column]\n",
        "        uniqueValues = numpy.unique(values)\n",
        "        if len(uniqueValues) == 1:\n",
        "            potentialSplits[column] = uniqueValues\n",
        "        else:\n",
        "            potentialSplits[column] = []\n",
        "            for i in range(len(uniqueValues)):\n",
        "                if i != 0:\n",
        "                    currentValue = uniqueValues[i]\n",
        "                    previousValue = uniqueValues[i - 1]\n",
        "                    potentialSplits[column].append((currentValue + previousValue) / 2)\n",
        "    return potentialSplits\n",
        "\n",
        "def splitData(data, splitColumn, splitValue):\n",
        "    splitColumnValues = data[:, splitColumn]\n",
        "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
        "\n",
        "def EntropyCalc(data):\n",
        "    _, uniqueClassesCounts = numpy.unique(data[:, -1], return_counts = True)\n",
        "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
        "    return sum(probabilities * -numpy.log2(probabilities))\n",
        "\n",
        "def TotalEntropy(dataBelow, dataAbove):\n",
        "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
        "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
        "    return pDataBelow * EntropyCalc(dataBelow) + pDataAbove * EntropyCalc(dataAbove)\n",
        "\n",
        "def BestSplit(data, potentialSplits, randomSplits = None):\n",
        "    overallEntropy = 9999\n",
        "    bestSplitColumn = 0\n",
        "    bestSplitValue = 0\n",
        "    if randomSplits == None:\n",
        "        for splitColumn in potentialSplits:\n",
        "            for splitValue in potentialSplits[splitColumn]:\n",
        "                dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "                currentOverallEntropy = TotalEntropy(dataBelow, dataAbove)\n",
        "                if currentOverallEntropy <= overallEntropy:\n",
        "                    overallEntropy = currentOverallEntropy\n",
        "                    bestSplitColumn = splitColumn\n",
        "                    bestSplitValue = splitValue\n",
        "    else:\n",
        "        for i in range(randomSplits):\n",
        "            randomSplitColumn = random.choice(list(potentialSplits))\n",
        "            randomSplitValue = random.choice(potentialSplits[randomSplitColumn])\n",
        "            dataBelow, dataAbove = splitData(data, randomSplitColumn, randomSplitValue)\n",
        "            currentOverallEntropy = TotalEntropy(dataBelow, dataAbove)\n",
        "            if currentOverallEntropy <= overallEntropy:\n",
        "                overallEntropy = currentOverallEntropy\n",
        "                bestSplitColumn = randomSplitColumn\n",
        "                bestSplitValue = randomSplitValue\n",
        "    return bestSplitColumn, bestSplitValue\n",
        "\n",
        "def DecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000, randomAttributes = None, randomSplits = None):\n",
        "    if currentDepth == 0:\n",
        "        global COLUMN_HEADERS\n",
        "        COLUMN_HEADERS = dataFrame.columns\n",
        "        data = dataFrame.values\n",
        "        if randomAttributes != None and randomAttributes <= len(COLUMN_HEADERS) - 1:\n",
        "            randomAttributes = random.sample(population = list(range(len(COLUMN_HEADERS) - 1)), k = randomAttributes)\n",
        "        else:\n",
        "            randomAttributes = None\n",
        "    else:\n",
        "        data = dataFrame\n",
        "    if puritycheck(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
        "        return dataclassification(data)\n",
        "    else:\n",
        "        currentDepth += 1\n",
        "        potentialSplits = PotentialSplit(data, randomAttributes)\n",
        "        splitColumn, splitValue = BestSplit(data, potentialSplits, randomSplits)\n",
        "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
        "            return dataclassification(data)\n",
        "        else:\n",
        "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
        "            decisionSubTree = {question: []}\n",
        "            yesAnswer = DecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
        "            noAnswer = DecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
        "            if yesAnswer == noAnswer:\n",
        "                decisionSubTree = yesAnswer\n",
        "            else:\n",
        "                decisionSubTree[question].append(yesAnswer)\n",
        "                decisionSubTree[question].append(noAnswer)\n",
        "            return decisionSubTree\n",
        "\n",
        "def SampleClassification(sample, decisionTree):\n",
        "    if not isinstance(decisionTree, dict):\n",
        "        return decisionTree\n",
        "    question = list(decisionTree.keys())[0]\n",
        "    attribute, value = question.split(\" <= \")\n",
        "    if sample[attribute] <= float(value):\n",
        "        answer = decisionTree[question][0]\n",
        "    else:\n",
        "        answer = decisionTree[question][1]\n",
        "    return SampleClassification(sample, answer)\n",
        "\n",
        "def PredictionDT(dataFrame, decisionTree):\n",
        "    predictions = dataFrame.apply(SampleClassification, axis = 1, args = (decisionTree,))\n",
        "    return predictions\n",
        "\n",
        "def AccuracyCalculate(predictedResults, category):\n",
        "    resultCorrect = predictedResults == category\n",
        "    return resultCorrect.mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(\"breast_cancer.csv\")\n",
        "df = df.drop(\"id\", axis = 1)\n",
        "df = df[df.columns.tolist()[1: ] + df.columns.tolist()[0: 1]]\n",
        "dfTrain, dfTest = Split(df, testSize = 0.25)"
      ],
      "metadata": {
        "id": "EtLvQo5baO5y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1804032: Decision Tree\")\n",
        "\n",
        "k = 1\n",
        "TrainAccuracy = 0\n",
        "while TrainAccuracy < 100:\n",
        "    decisionTree = DecisionTree(dfTrain, maxDepth = k)\n",
        "    decisionTreeTestResults = PredictionDT(dfTest, decisionTree)\n",
        "    TestAccuracy = AccuracyCalculate(decisionTreeTestResults, dfTest.iloc[:, -1]) * 100\n",
        "    decisionTreeTrainResults = PredictionDT(dfTrain, decisionTree)\n",
        "    TrainAccuracy = AccuracyCalculate(decisionTreeTrainResults, dfTrain.iloc[:, -1]) * 100\n",
        "    print(\"Depth = {}: \".format(k), end = \"\")\n",
        "    print(\"TestAccuracy = {0:.2f}%, \".format(TestAccuracy), end = \"\")\n",
        "    print(\"TrainAccuracy = {0:.2f}%\".format(TrainAccuracy), end = \"\\n\")\n",
        "    k += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocv7FfazQyxf",
        "outputId": "66c5ea32-c228-4345-e2a9-014558e9b01d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1804032: Decision Tree\n",
            "Depth = 1: TestAccuracy = 90.14%, TrainAccuracy = 92.27%\n",
            "Depth = 2: TestAccuracy = 90.14%, TrainAccuracy = 92.27%\n",
            "Depth = 3: TestAccuracy = 95.77%, TrainAccuracy = 96.72%\n",
            "Depth = 4: TestAccuracy = 95.77%, TrainAccuracy = 97.89%\n",
            "Depth = 5: TestAccuracy = 96.48%, TrainAccuracy = 99.53%\n",
            "Depth = 6: TestAccuracy = 95.77%, TrainAccuracy = 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mY6PMPbzatq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}